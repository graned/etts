version: "3.9"

###############################################################
#  ETTS – docker‑compose.yml
#  • GPU (NVIDIA) required
#  • Persists checkpoints and samples on the host
#  • Environment variables can be overridden in .env
###############################################################

services:
  etts_train:
    image: etts-train:latest # change to something like ghcr.io/your/etts if you push it
    build:
      context: . # Folder containing Dockerfile
    runtime: nvidia # Requires NVIDIA Container Toolkit
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    environment: # You can also keep these in a .env file
      PHONEME_DICT_PATH: train/dictionaries/phoneme_dict.json
      MANIFEST_PATH: train/manifests/etts_manifest.json
      CHECKPOINT_DIR: train/checkpoints
      SAMPLES_PATH: train/samples
      TRAIN_PHONEME_STEPS: 1
      TRAIN_PHONEME_MELS: 2
      TRAIN_EPOCHS: 100
      TRAIN_LR: 1e-3
    # volumes:
    # Mount your local folders to train the model
    # - ./checkpoints:/app/train/checkpoints # saves model checkpoints, gets created when train script is executed
    # - ./samples:/app/train/samples # required to train the model, see documentation to see expected format
    ports:
      - "6006:6006" # forward TensorBoard port (if you launch tb inside training)
    command: > # default – override with `docker compose run etts_train ...`
      python train/train_etts.py

  # --- OPTIONAL: run TensorBoard in its own container -------------------------
  tensorboard:
    image: tensorboard/tensorboard:2.16.2
    depends_on:
      - etts_train
    #volumes:
    #- ./logs:/logs
    ports:
      - "6006:6006"
    command: tensorboard --logdir=/logs --bind_all
